{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDkOflbCxorT"
   },
   "source": [
    "#Functions, correr esto es solo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tYbNBckSxoTP"
   },
   "outputs": [],
   "source": [
    "def file_names(path,file_type):\n",
    "    \"\"\"\n",
    "    To obtain a list with the name of the files with defined extension (filetype) on a certain folder (path)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : string\n",
    "        folder name where the images are stored\n",
    "\n",
    "    file_type : string\n",
    "        extension of the files to search for (e.g. tif, png, jpg)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F_Names : list\n",
    "        number of defined filetype files on the path folder\n",
    "    \"\"\"\n",
    "    \n",
    "    Names = []\n",
    "    for name in os.listdir(path):\n",
    "        name, extension = os.path.splitext(name)\n",
    "        if extension == file_type and name.find(\"ORG\") == -1:\n",
    "            if (name+\".tif.csv\") not in os.listdir(path):\n",
    "                image_name = name+extension\n",
    "                Names.append(image_name)\n",
    "    \n",
    "    #display information\n",
    "    #print(path+ '\\n')\n",
    "\n",
    "    im_count = len(Names)\n",
    "    im_fnames = []\n",
    "\n",
    "    for name in Names:\n",
    "        im_fnames.append(os.path.join(path, name))\n",
    "\n",
    "    # print('folder \"' +path.split('\\\\')[-1]+'\" = '+str(im_count) + ' files' + '\\n')\n",
    "    # print('file names:')\n",
    "    # print(Names)\n",
    "            \n",
    "    return(Names, im_fnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "li-GExGR1jpj"
   },
   "outputs": [],
   "source": [
    "def get_im_data(f_names):\n",
    "    \"\"\"\n",
    "    Load image data from a list of image files (f_names).\n",
    "    It doesn't supports images with different pixel dimentions\n",
    "    (e.g all of them have to be 900x600 px)\n",
    "    It is important for further positional correlations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f_name : string\n",
    "        file name including full path where images are stored, e.g. \"/folder/image_1.jpg\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ImsR,ImsG,ImsB: array_like\n",
    "        data per channel of each image (ImsR -> matrix size = (W,H,image_count/x_frames))\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    W,H,_ = plt.imread(fnames[0]).shape      # Measure the image size based on the first image on the folder\n",
    "    N = len(fnames) \n",
    "    Ims_R = np.zeros((W,H,N))\n",
    "    Ims_G = np.zeros((W,H,N))\n",
    "    Ims_B = np.zeros((W,H,N))\n",
    "    Ims_Sum = np.zeros((W,H,N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        Im = plt.imread(f_names[0])\n",
    "        Ims_R[:,:,i] = Im[:,:,0]              # Last number code the channel: 0=red, 1=green, 2=blue\n",
    "        Ims_G[:,:,i] = Im[:,:,1]\n",
    "        Ims_B[:,:,i] = Im[:,:,2]\n",
    "        \n",
    "        Chan_Sum = np.sum(Im, axis=2) #sum channels\n",
    "        max_imValue = np.amax(Chan_Sum, axis = (0,1)) #get the maximum im value\n",
    "        \n",
    "        if max_imValue < 1: #make sure it is higher than 1 to avoid division problems\n",
    "            max_imValue = 1\n",
    "            \n",
    "        Ims_Sum[:,:,i] = Chan_Sum*255/max_imValue #normalize and store the value\n",
    "    plt.clf()\n",
    "    return(Ims_R,Ims_G,Ims_B,Ims_Sum)\n",
    "\n",
    "# at call you can take only the channels you are interested in (e.g.):\n",
    "# red,_,blue=get_im_data(f_names)  ---> this only takes the red and blue channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "o_BcgNMR1kat"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MARIO VERA VELIZ\\\\Downloads\\\\fotos r1\\\\3um\\\\FK2021CL_(260)-Profundidad de enfoque extendida-01-Exportar imagen-10\\\\FK2021CL_(260)-Profundidad de enfoque extendida-01-Exportar imagen-10_m01_DAPI.tif'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3taur4AT1klT"
   },
   "outputs": [],
   "source": [
    "def colony_blobs_id(data, thresh, im_name, sigma_lim=[1,10], filename='null', xlim='null', ylim='null'):\n",
    "    \"\"\"\n",
    "    Use skimage to identify the position of each colony and define the circular region\n",
    "    used by each of them\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: array of single channel image data\n",
    "\n",
    "    thresh:\n",
    "        Pixel values > thresh are included in the analysis, range (0,1)\n",
    "        \n",
    "    im_name:\n",
    "        Name of an image on which to overlay colony positions and sizes\n",
    "    \n",
    "    filename: string\n",
    "        filename with whom save the output image+blobs+ID\n",
    "    \n",
    "    sigma_lim: list\n",
    "        list with lower and upper sigma limits [min_sigma, max_sigma]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A: array (Nx3)\n",
    "        Contains the (y,x) position and size of each blob for each of N colonies detected\n",
    "    \"\"\"\n",
    "    \n",
    "    #Show thresholded image\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(data>thresh)\n",
    "    plt.title('Thresh Image')\n",
    "    \n",
    "    if xlim != 'null' and ylim != 'null':\n",
    "        data2 = data[ylim[0]:ylim[1],xlim[0]:xlim[1]]\n",
    "    else:\n",
    "        data2 = data  #this is necesary to avoid conflicts in plot_blobs dimetions\n",
    "    \n",
    "    # Find the blobs\n",
    "    A = skfeat.blob_log(data2, min_sigma=sigma_lim[0], max_sigma=sigma_lim[1], num_sigma=10, \n",
    "                    threshold=thresh, overlap=0.2)\n",
    "    # A =[y,x,sigma]\n",
    "    col_values = np.zeros((A.shape[0],A.shape[1]+2))\n",
    "    col_values[:,0:3] = A\n",
    "        \n",
    "    radii = ((2)**(1/2))*col_values[:,2]\n",
    "    col_values[:,3] = radii   # store the radii\n",
    "    \n",
    "    col_values[:,4]=np.arange(col_values.shape[0])  #assign the ID column\n",
    "    \n",
    "    #make plots\n",
    "    # plot_blobs(col_values, data, ylim, xlim)\n",
    "    # colony_plot(col_values,im_name, ylim, xlim)\n",
    "    \n",
    "    #plot the histogram of the size of the colonies\n",
    "    #plt.figure()\n",
    "    # plt.hist(col_values[:,3])\n",
    "    # plt.title('colonies size distribution')\n",
    "    # plt.ylabel('number of colonies')\n",
    "    # plt.xlabel('Radius[px]')\n",
    "    \n",
    "    \n",
    "    # if filename != 'null':\n",
    "    #      plt.savefig(str(filename) + \".pdf\", transparent=True)\n",
    "    plt.clf()\n",
    "    return(col_values)\n",
    "\n",
    "#col_values = [x,y,sigma, radii, col_ID]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cmoDQ4Tu1kvh"
   },
   "outputs": [],
   "source": [
    "def plot_blobs(colonies, data, ylim='null', xlim='null'):\n",
    "    \n",
    "    if xlim != 'null' and ylim != 'null':\n",
    "        data = data[ylim[0]:ylim[1],xlim[0]:xlim[1]]  #2 dim data --> R or G or B or sum of them\n",
    "        colonies = colonies[colonies[:,1]<xlim[1],:]\n",
    "        colonies = colonies[colonies[:,1]>xlim[0],:]\n",
    "        colonies = colonies[colonies[:,0]<ylim[1],:]\n",
    "        colonies = colonies[colonies[:,0]>ylim[0],:]\n",
    "        colonies[:,1] = colonies[:,1]-xlim[0]\n",
    "        colonies[:,0] = colonies[:,0]-ylim[0]\n",
    "    \n",
    "    xpos=colonies[:,1]\n",
    "    ypos=colonies[:,0]\n",
    "    #radii = ((2)**(1/2))*col_sig\n",
    "    radii = colonies[:,3]\n",
    "    \n",
    "    fig_norm = plt.figure(figsize=(8,8))\n",
    "    # plt.imshow(data, cmap='gray')\n",
    "    # plt.colorbar()\n",
    "    # plt.title('normalized image')\n",
    "    # print('found ' + str(len(colonies))+' colonies')\n",
    "    for i in range(len(colonies)):\n",
    "        circle = plt.Circle((xpos[i], ypos[i]), radii[i], color='r', fill=False , \n",
    "                            lw=0.5)\n",
    "        fig = plt.gcf()\n",
    "        ax = fig.gca()\n",
    "        ax.add_artist(circle)\n",
    "    plt.clf()\n",
    "    return()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qxtay9b-28Zx"
   },
   "outputs": [],
   "source": [
    "def colony_plot(colonies,im_name, ylim, xlim):\n",
    "    \n",
    "    if xlim != 'null' and ylim != 'null':\n",
    "        im = plt.imread(im_name)[ylim[0]:ylim[1],xlim[0]:xlim[1],:]\n",
    "        colonies = colonies[colonies[:,1]<xlim[1],:]\n",
    "        colonies = colonies[colonies[:,1]>xlim[0],:]\n",
    "        colonies = colonies[colonies[:,0]<ylim[1],:]\n",
    "        colonies = colonies[colonies[:,0]>ylim[0],:]\n",
    "        colonies[:,1] = colonies[:,1]-xlim[0]\n",
    "        colonies[:,0] = colonies[:,0]-ylim[0]\n",
    "        \n",
    "    else:\n",
    "        im = plt.imread(im_name)\n",
    "    \n",
    "    xpos=colonies[:,1]\n",
    "    ypos=colonies[:,0]\n",
    "    col_sig = colonies[:,2]\n",
    "    #radii = ((2)**(1/2))*col_sig\n",
    "    radii = colonies[:,3]\n",
    "    ID = colonies[:,4]\n",
    "\n",
    "    fig_im = plt.figure(figsize=(8,8))\n",
    "    #plt.imshow(im)\n",
    "    im_name = im_name.split('\\\\')[-1]\n",
    "    plt.title('Over \"'+ im_name+'\"')\n",
    "    \n",
    "    for i in range(len(colonies)):\n",
    "        # plot the circle area identified for each colony\n",
    "        #circle = plt.Circle((A[i,1], A[i,0]), 2*A[i,2], color='w', fill=False , lw=0.5)\n",
    "        circle = plt.Circle((xpos[i], ypos[i]), radii[i], color='w', fill=False , lw=0.5)\n",
    "        fig = plt.gcf()\n",
    "        ax = fig.gca()\n",
    "        ax.add_artist(circle)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # attach the ID label to each colony\n",
    "        plt.annotate(ID[i], xy=(xpos[i], ypos[i]), xytext=(-2, 2),\n",
    "                     textcoords='offset points', ha='right', va='bottom',\n",
    "                     color='white')\n",
    "    plt.clf()\n",
    "    return()\n",
    "\n",
    "def smooth_data(data,sigma, im_number, row = 'middle'):\n",
    "\n",
    "    \"\"\"\n",
    "    Apply gaussian filter to smooth each frame data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dictionary\n",
    "        4 dimensional (R,G,B, and im_number) matrix with the data.\n",
    "        \n",
    "    sigma: double\n",
    "        Filter parameter (standard deviation)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    NSIms: dictionary\n",
    "        Sum over time of Smoothed data per channel (call it nsims[channel][r,c])\n",
    "\n",
    "    NSImsAll: array_like\n",
    "        Matrix with sum of nsims over the channels (call it nsimsAll[r,c])\n",
    "    \n",
    "    SImsT: dictionary\n",
    "        Smoothed data per channel per frame (call it as simsT[channel][r,c,f])\n",
    "\n",
    "    \"\"\"\n",
    "    CHANNELS = ['R', 'G', 'B']\n",
    "    NSIms = {}\n",
    "    NSIms_All = np.zeros((data[CHANNELS[0]].shape[0],\n",
    "                          data[CHANNELS[0]].shape[1]))\n",
    "    \n",
    "    NIm_All = np.zeros((NSIms_All.shape))\n",
    "    \n",
    "    plt.figure(figsize=(17,3))\n",
    "    POS_VECT = [131,132,133]           # figure position vector\n",
    "    count = 0\n",
    "\n",
    "    for c in CHANNELS:\n",
    "        # apply filter\n",
    "        #Data_Sum = data[c].sum(axis=2)\n",
    "        SIms = gaussian(data[c][:,:,im_number], sigma)\n",
    "        \n",
    "        px_dist = (SIms-SIms.min())\n",
    "        max_dist =(SIms.max()-SIms.min())\n",
    "        \n",
    "        if max_dist < 1:    # to avoid problems of <1 division\n",
    "            max_dist = 1\n",
    "            \n",
    "        NSIms [c] = px_dist/max_dist  # nomalization, pixel value ∈ [0,1]\n",
    "\n",
    "        NSIms_All += NSIms[c]\n",
    "        \n",
    "      \n",
    "        # make plot of the sum over time of smoothed data per channel\n",
    "    \n",
    "        # plt.subplot(POS_VECT[count])\n",
    "        # plt.imshow(NSIms[c])\n",
    "        # plt.colorbar()\n",
    "        # plt.title(c+' channel')\n",
    "    \n",
    "        count += 1\n",
    "    \n",
    "        ##### original image normalization\n",
    "        px_d2 = (SIms-SIms.min())\n",
    "        max_d2 =(SIms.max()-SIms.min())\n",
    "        \n",
    "        if max_d2 < 1:    # to avoid problems of <1 division\n",
    "            max_d2 = 1\n",
    "            \n",
    "        NIm = px_d2/max_d2  # nomalization, pixel value ∈ [0,1]\n",
    "        NIm_All += NIm\n",
    "        \n",
    "    #plot the transect\n",
    "    row_transect(NIm_All,'Original Image')\n",
    "    row_transect(NSIms_All,'Smoothed Image')\n",
    "    \n",
    "    plt.clf()\n",
    "    return(NSIms,NSIms_All)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q2ePirRZ28jJ"
   },
   "outputs": [],
   "source": [
    "def row_transect(data, title,  row = -1):\n",
    "    \"\"\"\n",
    "    Plot the value of a transect (row of pixels) in a frame and plot it\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dictionary\n",
    "        dictionary with the R G B data of all images, and his names on Data['Im']\n",
    "\n",
    "    row : int\n",
    "        row where you want to see the transect\n",
    "        \n",
    "    title: string\n",
    "        Whole figure title\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if row == -1:\n",
    "        row = int(data.shape[0]/2)\n",
    "    else:\n",
    "        row = int(row)  #just in case a non integer number is given\n",
    "    \n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(data[row,:])\n",
    "    plt.xlabel('pixels')\n",
    "    plt.ylabel('value')\n",
    "    plt.title('Transect')\n",
    "\n",
    "    #plot selected line transect on the image      \n",
    "    plt.subplot(122)    \n",
    "    S1,S2 = data.shape\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.gca()\n",
    "    ax.imshow(data)\n",
    "    rect = matplotlib.patches.Rectangle((0,row), S2, 0, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    plt.title('Sumarized image')\n",
    "    \n",
    "    fig.suptitle(str(title), fontsize=16)\n",
    "    plt.subplots_adjust(left=0.1, wspace=0.1, top=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "s3laicDc28s8"
   },
   "outputs": [],
   "source": [
    "def im_zoom(x_lims, y_lims, imagen, colorbar = True):\n",
    "    \"\"\"\n",
    "    Make a zoom of a region of interest in an image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        xlims: list\n",
    "            x-axis limits of the zoomed section. \n",
    "            e.g. [x_min, x_max]\n",
    "\n",
    "        ylims: list\n",
    "            y-axis limits of the zoomed section. \n",
    "            e.g. [y_min, y_max]\n",
    "\n",
    "        imagen: numpy array\n",
    "            the imagen array to be display\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    X2R = x_lims[1]-x_lims[0] #convert on steps because the rectangle patch definition\n",
    "    Y2R = y_lims[1]-y_lims[0]\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    #plt.imshow(imagen)\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.gca()\n",
    "    rect = matplotlib.patches.Rectangle((y_lims[0],x_lims[0]), Y2R, X2R, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(imagen[x_lims[0]:x_lims[1],y_lims[0]:y_lims[1]])\n",
    "    if colorbar == True:\n",
    "        plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MmwRTlKh282D"
   },
   "outputs": [],
   "source": [
    "def binary_image(im_data, upper, lower):\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(im_data)\n",
    "    \n",
    "    bin_high = im_data < upper     \n",
    "          \n",
    "    #if isinstance(lower,(float,int)):  #check valid input\n",
    "        \n",
    "    bin_low = im_data > lower\n",
    "        \n",
    "    #bin_grain = np.multiply(1*bin_high,1*bin_low)\n",
    "    bin_grain = np.multiply(bin_high,bin_low)\n",
    "        \n",
    "    plt.figure(figsize=(8,8))\n",
    "    #plt.imshow(bin_grain)\n",
    "    \n",
    "    grain_area = sum(sum(1*bin_grain))\n",
    "    print('Grain area is: '+str(grain_area) + ' pixels')\n",
    "    \n",
    "    plt.clf()\n",
    "    return(bin_grain, grain_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sdQ0hCN73O-e"
   },
   "outputs": [],
   "source": [
    "def Bfield_filter(colonies, bf_bin):\n",
    "    filtered = []\n",
    "    for i in range(len(colonies)):\n",
    "        x = int(colonies[i,1])\n",
    "        y = int(colonies[i,0])\n",
    "        \n",
    "        if bf_bin[y,x] == True:\n",
    "            \n",
    "            filtered.append(colonies[i,:])  \n",
    "    \n",
    "    return(filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgap1c4o3PGw",
    "outputId": "7b68f95c-2d18-4ab8-8a53-2ce285d62c35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if False:\\n    def BF_area_filter(colonies, bf_bin):\\n        filtered = []\\n        for i in range(len(colonies)):\\n            x = int(colonies[i,1])\\n            y = int(colonies[i,0])\\n            r = colonies[i,3]\\n            \\n            circle = np.zeros((r,r))\\n            for n in r:\\n                for m in r:\\n                    if (n*n)+(m*m)<(r*r):\\n                        circle(n,m) = 1\\n            total = np.sum(np.sum(circle))\\n            \\n            #now, make a dot product between \\n            \\n            \\n            if bf_bin[y,x] == True:\\n\\n                filtered.append(colonies[i,:])  \\n\\n        return(filtered) '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "\"\"\"if False:\n",
    "    def BF_area_filter(colonies, bf_bin):\n",
    "        filtered = []\n",
    "        for i in range(len(colonies)):\n",
    "            x = int(colonies[i,1])\n",
    "            y = int(colonies[i,0])\n",
    "            r = colonies[i,3]\n",
    "            \n",
    "            circle = np.zeros((r,r))\n",
    "            for n in r:\n",
    "                for m in r:\n",
    "                    if (n*n)+(m*m)<(r*r):\n",
    "                        circle(n,m) = 1\n",
    "            total = np.sum(np.sum(circle))\n",
    "            \n",
    "            #now, make a dot product between \n",
    "            \n",
    "            \n",
    "            if bf_bin[y,x] == True:\n",
    "\n",
    "                filtered.append(colonies[i,:])  \n",
    "\n",
    "        return(filtered) \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zDXmWKgB3Vjh"
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name, folder, im_folder_path):\n",
    "    # folder is the name of the data folder\n",
    "    # name is the name of the database file\n",
    "    # im_folder is used as the dictionary identifier for the experiment data.\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    database = load_obj(name, folder)\n",
    "    \n",
    "    im_folder = im_folder_path.split('\\\\')[-1]\n",
    "    database[im_folder] = obj\n",
    "    \n",
    "    with open(folder+'/'+ name + '.pkl', 'wb') as f:\n",
    "        pkl.dump(database, f, pkl.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        print('\"'+ name + '.pkl\" saved on folder \"'+ folder +'\"')\n",
    "\n",
    "def load_obj(name, folder ):\n",
    "    try:\n",
    "        with open(folder+'/' + name + '.pkl', 'rb') as f:\n",
    "            return pkl.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print('there was any previous file')\n",
    "        empty_dict = {}\n",
    "        return(empty_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a0v1-kfBqGgr"
   },
   "outputs": [],
   "source": [
    "def imageToCsv(y, im_data, fnames, Im_ID):\n",
    "    Im_ID = {}\n",
    "    Im_ID['dapi'] = fnames[y]\n",
    "    Im_ID['bf'] = fnames[y]\n",
    "\n",
    "    #initialize the dictionaries to store the data\n",
    "    sImS = {}\n",
    "    sImSall = {}\n",
    "    detected={}\n",
    "    filter_sigma = {}\n",
    "    threshold = {}\n",
    "    sigma_lim = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Fill this two variables to set the filter properties\n",
    "    im_num = y\n",
    "    filter_sigma[im_num] = 0.4\n",
    "\n",
    "    print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "    #### apply the filter\n",
    "    sImS[im_num],sImSall[im_num] = smooth_data(im_data,filter_sigma[im_num],im_num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # perform a Zoom by slicing the image:\n",
    "\n",
    "    # modify next values accord the section you want to see:\n",
    "\n",
    "    x_lims = [1000,1500]    \n",
    "    y_lims = [1500,2000]    \n",
    "\n",
    "    #######################\n",
    "    # Just make the plot ###\n",
    "    ########################\n",
    "    im_zoom(x_lims, y_lims, sImSall[im_num])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # assign the stimated radius value in pixel units\n",
    "\n",
    "    Rmin = 1   # --> this should be estimated based on microscope resolution and bacterial size\n",
    "    Rmax = 10\n",
    "\n",
    "    #perform the sigma limits computation:\n",
    "    sigma_lim[im_num] = [Rmin/(2**0.5),Rmax/(2**0.5)]\n",
    "    print('sigma limits are: ' + str(sigma_lim[im_num]))\n",
    "\n",
    "\n",
    "    #define a Threshold\n",
    "    threshold[im_num]=0.7 #CAMBIE ESTO PARA LOS CUPONES\n",
    "\n",
    "    ##########################\n",
    "    ## evaluate it visually ##\n",
    "    ##########################\n",
    "\n",
    "    # whole image\n",
    "    thr_im = sImSall[im_num]>threshold[im_num]\n",
    "    #plt.imshow(thr_im)\n",
    "\n",
    "    # zoom\n",
    "    x_lims = [1000,2000]    \n",
    "    y_lims = [2000,3000]    \n",
    "    im_zoom(x_lims, y_lims, thr_im, colorbar = False)\n",
    "\n",
    "    ## Fill this two parameters only if you want to use a smaller region of the image (it's useful to verify the correct parameter choise)\n",
    "    x_lims = [1000,2000]    \n",
    "    y_lims = [2000,3000] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    ### detect the images ###\n",
    "    #########################\n",
    "\n",
    "    detected[im_num]=colony_blobs_id(sImSall[im_num], threshold[im_num], fnames[im_num], sigma_lim[im_num])#, xlim=x_lim, ylim=y_lim) \n",
    "    \n",
    "    y_zoom = [500,800]\n",
    "    x_zoom = [200,500]\n",
    "    #colony_plot(detected[im_num], fnames[im_num], y_zoom, x_zoom)\n",
    "\n",
    "\n",
    "    # image number correspont to the brighfield\n",
    "    bf_num = im_data['name'].index(Im_ID['bf'])\n",
    "    print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "    ###########################################################\n",
    "    # fill this variable with desired filter parameter value:\n",
    "\n",
    "    filter_sigma[bf_num] = 0.5\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    # Apply the filter\n",
    "    sImS[bf_num],sImSall[bf_num] = smooth_data(im_data,filter_sigma[bf_num],bf_num)\n",
    "\n",
    "\n",
    "    bf_cols = {}\n",
    "\n",
    "    ####################################################\n",
    "    ## Fill this parameters based on the image values ##\n",
    "\n",
    "    thresh_up = 3   # grain threshold\n",
    "    thresh_low = 0     # border threshold\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    bf_cols[\"bf_threshold\"] = [thresh_up, thresh_low]  # save the used values\n",
    "    bin_bf, grain_area = binary_image(sImSall[bf_num], thresh_up, thresh_low)\n",
    "\n",
    "    print(\"image percent \" + str(grain_area/bin_bf.size))\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    image = 'dapi'   # write \"dapi\" or \"dii\"\n",
    "\n",
    "    ###################################################################\n",
    "    im_num = im_data['name'].index(Im_ID[image])\n",
    "    print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "    bf_cols[im_num] =  np.asarray(Bfield_filter(detected[im_num], bin_bf))\n",
    "    y_zoom = [200,600]\n",
    "    x_zoom = [300,780]\n",
    "    #colony_plot(bf_cols[im_num], fnames[im_num], ylim = y_zoom, xlim = x_zoom)\n",
    "    #print('grain filtered colonies')\n",
    "\n",
    "    #colony_plot(detected[im_num], fnames[im_num], ylim = y_zoom, xlim = x_zoom)\n",
    "\n",
    "    #print('previous grain filter')\n",
    "\n",
    "    import csv\n",
    "    im_clases = ['dapi']        # They have to be in Im_ID.keys()\n",
    "    Headers = ['Dye', 'Y', 'X', 'Sigma' , 'Radii', 'ID']   # Y to ID are in \"detected\"\n",
    "\n",
    "    exp_name = fnames[y]   # experiment name to be create the file                            #######\n",
    "\n",
    "    with open(exp_name+'.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                              quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(Headers)\n",
    "      \n",
    "        for image in im_clases:\n",
    "            im_num = im_data['name'].index(Im_ID[image])\n",
    "          \n",
    "            for colony in bf_cols[im_num]:\n",
    "                new_line = [image]\n",
    "                for value in colony:\n",
    "                    new_line.append(value)\n",
    "                  \n",
    "                filewriter.writerow(new_line)\n",
    "    plt.clf()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RErlYDO9yvwv"
   },
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2qr4bOUuyv-N"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "#modify some matplotlib parameters to manage the images for illustrator\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "import skimage.feature as skfeat\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyO4t-tJyiS8"
   },
   "source": [
    "# Upload folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSw5hul3yiyC",
    "outputId": "40174d7d-bb21-4583-b661-d6fc18b019a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Image_analysis_folders' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#Clone github\n",
    "!git clone https://github.com/OSOMONOSO/Image_analysis_folders\n",
    "MainFolder = './Image_analysis_folders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgsMNjLyofgx"
   },
   "outputs": [],
   "source": [
    "MainFolder = './Image_analysis_folders'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itQ_Cf80gWDz"
   },
   "source": [
    "#Upload foders drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVCN44UkinDn",
    "outputId": "fabd4097-9662-49bf-dbf6-5277a5abcca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MUJn-rukgZdo"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#MainFolder ='/content/gdrive/MyDrive/fotos r1/46um' # 3um, 15um, 46um, Org\n",
    "MainFolder ='fotos r1/3um' # 3um, 15um, 46um, Org\n",
    "\n",
    "data = os.listdir(MainFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsc6hpXFS9-q"
   },
   "source": [
    "# Ciclo for para imagenes dentro de una carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErbaLcqtAoB6"
   },
   "outputs": [],
   "source": [
    "#Delete all folders\n",
    "#%rm -rf Image_analysis_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDQcazEVmiSZ",
    "outputId": "8c8a3666-3108-4d56-9d5f-c3435e178217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-eefe90baa1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mim_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'R'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'G'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NormSum'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_im_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mim_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# ID bright and dapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-88d68a69ba95>\u001b[0m in \u001b[0;36mget_im_data\u001b[1;34m(f_names)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m      \u001b[1;31m# Measure the image size based on the first image on the folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mIms_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "#Upload folder and detect where it is\n",
    "data = os.listdir(MainFolder)\n",
    "df = pd.DataFrame(data, columns=['Folder'])\n",
    "df.sort_values(by=['Folder'], inplace=True)\n",
    "df = df.iloc[0::, 0] #[1::, 0] si la primera imagen está defectuosa\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "largo_data = df.count()\n",
    "\n",
    "im_extension = '.tif'\n",
    "\n",
    "for x in range(largo_data):\n",
    "\n",
    "  nested_folder = (MainFolder + \"/\" + df[x]+\"/\")\n",
    "  fpath = os.path.abspath(nested_folder)\n",
    "  im_names, fnames = file_names(fpath, im_extension)\n",
    "  Im_ID = {}\n",
    "  im_data = {}\n",
    "  if len(fnames) == 0:\n",
    "    print(\"Nada que procesar en el fichero:\", nested_folder)\n",
    "  else:\n",
    "    print(len(fnames))\n",
    "    im_data['R'], im_data['G'], im_data['B'], im_data['NormSum'] = get_im_data(fnames)\n",
    "    im_data['name'] = fnames\n",
    "    # ID bright and dapi\n",
    "    f_categories = list(Im_ID.keys())\n",
    "    for cat in f_categories:\n",
    "      print(str(cat) + ' file is: \\n' + str(Im_ID[cat]) + '\\n')\n",
    "    for y in range(0, len(fnames)):\n",
    "        print(y, \"de \", len(fnames))\n",
    "        # to store the related image source\n",
    "        # also define a vector with the channels\n",
    "        imageToCsv(y, im_data, fnames, Im_ID)\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FYvT6VhIkoZ7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MARIO VERA VELIZ\\\\Downloads\\\\fotos r1\\\\3um\\\\FK2021CL_(260)-Profundidad de enfoque extendida-01-Exportar imagen-10\\\\FK2021CL_(260)-Profundidad de enfoque extendida-01-Exportar imagen-10_m02_DAPI.tif'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzvbNOLMOXeP"
   },
   "outputs": [],
   "source": [
    "#Upload folder and detect where it is\n",
    "data = os.listdir(MainFolder)\n",
    "df = pd.DataFrame(data, columns=['Folder'])\n",
    "df.sort_values(by=['Folder'], inplace=True)\n",
    "df = df.iloc[1::,0]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "largo_data = df.count()\n",
    "\n",
    "im_extension = 'DAPI.tif'\n",
    "for x in range(largo_data): \n",
    "  nested_folder = ( MainFolder + \"/\" + df[x])\n",
    "  fpath = os.path.abspath(nested_folder)\n",
    "  im_names, fnames = file_names(fpath,im_extension)\n",
    "\n",
    "  for x in range (largo_data):\n",
    "\n",
    "    #ID bright and dapi\n",
    "    Im_ID = {}\n",
    "    Im_ID['dapi'] = fnames[x]\n",
    "    Im_ID['bf'] = fnames[x]\n",
    "\n",
    "    f_categories = list(Im_ID.keys())\n",
    "    for cat in f_categories:\n",
    "        print(str(cat) + ' file is: \\n'+ str(Im_ID[cat]) +'\\n' )\n",
    "\n",
    "    \n",
    "    \n",
    "    # to store the related image source\n",
    "    # also define a vector with the channels\n",
    "    im_data={}\n",
    "    im_data['R'],im_data['G'],im_data['B'],im_data['NormSum'] = get_im_data(fnames)\n",
    "    im_data['name']=fnames    \n",
    "    CHANNELS=['R','G','B']\n",
    "\n",
    "\n",
    "    \n",
    "    #initialize the dictionaries to store the data\n",
    "    sImS = {}\n",
    "    sImSall = {}\n",
    "    detected={}\n",
    "    filter_sigma = {}\n",
    "    threshold = {}\n",
    "    sigma_lim = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Fill this two variables to set the filter properties\n",
    "    im_num = x\n",
    "    filter_sigma[im_num] = 0.4\n",
    "\n",
    "    print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "    #### apply the filter\n",
    "    sImS[im_num],sImSall[im_num] = smooth_data(im_data,filter_sigma[im_num],im_num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # perform a Zoom by slicing the image:\n",
    "\n",
    "    # modify next values accord the section you want to see:\n",
    "\n",
    "    x_lims = [1000,1500]    \n",
    "    y_lims = [1500,2000]    \n",
    "\n",
    "    #######################\n",
    "    # Just make the plot ###\n",
    "    ########################\n",
    "    im_zoom(x_lims, y_lims, sImSall[im_num])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # assign the stimated radius value in pixel units\n",
    "\n",
    "    Rmin = 1   # --> this should be estimated based on microscope resolution and bacterial size\n",
    "    Rmax = 10\n",
    "\n",
    "    #perform the sigma limits computation:\n",
    "    sigma_lim[im_num] = [Rmin/(2**0.5),Rmax/(2**0.5)]\n",
    "    print('sigma limits are: ' + str(sigma_lim[im_num]))\n",
    "\n",
    "\n",
    "    #define a Threshold\n",
    "    threshold[im_num]=0.7 #CAMBIE ESTO PARA LOS CUPONES\n",
    "\n",
    "    ##########################\n",
    "    ## evaluate it visually ##\n",
    "    ##########################\n",
    "\n",
    "    # whole image\n",
    "    thr_im = sImSall[im_num]>threshold[im_num]\n",
    "    #plt.imshow(thr_im)\n",
    "\n",
    "    # zoom\n",
    "    x_lims = [1000,2000]    \n",
    "    y_lims = [2000,3000]    \n",
    "    im_zoom(x_lims, y_lims, thr_im, colorbar = False)\n",
    "\n",
    "    ## Fill this two parameters only if you want to use a smaller region of the image (it's useful to verify the correct parameter choise)\n",
    "    x_lims = [1000,2000]    \n",
    "    y_lims = [2000,3000] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    ### detect the images ###\n",
    "    #########################\n",
    "\n",
    "    detected[im_num]=colony_blobs_id(sImSall[im_num], threshold[im_num], fnames[im_num], sigma_lim[im_num])#, xlim=x_lim, ylim=y_lim) \n",
    "    \n",
    "    y_zoom = [500,800]\n",
    "    x_zoom = [200,500]\n",
    "    colony_plot(detected[im_num], fnames[im_num], y_zoom, x_zoom)\n",
    "\n",
    "\n",
    "    # image number correspont to the brighfield\n",
    "    bf_num = im_data['name'].index(Im_ID['bf'])\n",
    "    print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "    ###########################################################\n",
    "    # fill this variable with desired filter parameter value:\n",
    "\n",
    "    filter_sigma[bf_num] = 0.5\n",
    "\n",
    "    ############################################################\n",
    "\n",
    "    # Apply the filter\n",
    "    sImS[bf_num],sImSall[bf_num] = smooth_data(im_data,filter_sigma[bf_num],bf_num)\n",
    "\n",
    "\n",
    "    bf_cols = {}\n",
    "\n",
    "    ####################################################\n",
    "    ## Fill this parameters based on the image values ##\n",
    "\n",
    "    thresh_up = 3   # grain threshold\n",
    "    thresh_low = 0     # border threshold\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    bf_cols[\"bf_threshold\"] = [thresh_up, thresh_low]  # save the used values\n",
    "    bin_bf, grain_area = binary_image(sImSall[bf_num], thresh_up, thresh_low)\n",
    "\n",
    "    print(\"image percent \" + str(grain_area/bin_bf.size))\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    image = 'dapi'   # write \"dapi\" or \"dii\"\n",
    "\n",
    "    ###################################################################\n",
    "    im_num = im_data['name'].index(Im_ID[image])\n",
    "    print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "    bf_cols[im_num] =  np.asarray(Bfield_filter(detected[im_num], bin_bf))\n",
    "    y_zoom = [200,600]\n",
    "    x_zoom = [300,780]\n",
    "    #colony_plot(bf_cols[im_num], fnames[im_num], ylim = y_zoom, xlim = x_zoom)\n",
    "    #print('grain filtered colonies')\n",
    "\n",
    "    #colony_plot(detected[im_num], fnames[im_num], ylim = y_zoom, xlim = x_zoom)\n",
    "\n",
    "    #print('previous grain filter')\n",
    "\n",
    "    import csv\n",
    "    im_clases = ['dapi']        # They have to be in Im_ID.keys()\n",
    "    Headers = ['Dye', 'Y', 'X', 'Sigma' , 'Radii', 'ID']   # Y to ID are in \"detected\"\n",
    "\n",
    "    exp_name = fnames[x]   # experiment name to be create the file                            #######\n",
    "\n",
    "    with open(exp_name+'.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                              quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(Headers)\n",
    "      \n",
    "        for image in im_clases:\n",
    "            im_num = im_data['name'].index(Im_ID[image])\n",
    "          \n",
    "            for colony in bf_cols[im_num]:\n",
    "                new_line = [image]\n",
    "                for value in colony:\n",
    "                    new_line.append(value)\n",
    "                  \n",
    "                filewriter.writerow(new_line)\n",
    "\n",
    "\n",
    "  #metada\n",
    "\n",
    "  \"\"\"\n",
    "  m_headers = ['Image','Parameter', 'Value']\n",
    "\n",
    "  s_min = {}\n",
    "  s_max = {}\n",
    "\n",
    "  for i in list(sigma_lim.keys()):\n",
    "      s_min[i] = sigma_lim[i][0]\n",
    "      s_max[i] = sigma_lim[i][1]\n",
    "\n",
    "  param_values = {\n",
    "      'smooth' : filter_sigma,\n",
    "      'threshold': threshold,\n",
    "      'sigma_min': s_min,\n",
    "      'sigma_max': s_max\n",
    "  } \n",
    "\n",
    "  parameters = list(param_values.keys())\n",
    "\n",
    "  with open(\"metadata_\"+exp_name+'.csv', 'w') as csvfile:\n",
    "      filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "      filewriter.writerow(m_headers)\n",
    "    \n",
    "      for image in im_clases:\n",
    "          im_num = im_data['name'].index(Im_ID[image])\n",
    "        \n",
    "          for param in parameters:\n",
    "              new_line = []\n",
    "              new_line.append(Im_ID[image])            #add image name\n",
    "              new_line.append(param)                   #add param name \n",
    "              new_line.append(param_values[param][im_num])   #add image name\n",
    "                \n",
    "              filewriter.writerow(new_line)\"\"\"\n",
    "\n",
    "\n",
    "  fpath.split('\\\\')[-1]\n",
    "\n",
    "  ### Organize the information, it is not necessary to modify anything here.\n",
    "  filtered_images = {}\n",
    "  filtered_images['images'] = sImS\n",
    "  filtered_images['filter_sigma'] = filter_sigma\n",
    "\n",
    "  images_data = {}\n",
    "  images_data[\"smooth\"] = filter_sigma\n",
    "  images_data[\"detection\"] = {}\n",
    "  images_data[\"detection\"]['colonies'] = detected\n",
    "  images_data[\"detection\"]['threshold'] = threshold\n",
    "  images_data[\"detection\"]['sigma_domain'] = sigma_lim\n",
    "  images_data[\"detection\"]['bf_colonies'] = bf_cols\n",
    "\n",
    "  #Save the data\n",
    "  save_obj(images_data, 'database', 'data', fpath)\n",
    "\n",
    "  data2 = load_obj('database', 'data')\n",
    "\n",
    "  data2.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkoUQ-QsEty7"
   },
   "source": [
    "# Sección nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJVuzUxg4ScD"
   },
   "outputs": [],
   "source": [
    "#%cd ..\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQ69LlXLQ8AV"
   },
   "outputs": [],
   "source": [
    "#concatenar todos los archivos .csv\n",
    "\n",
    "\n",
    "data = os.listdir(MainFolder)\n",
    "df2 = pd.DataFrame(data, columns=['Folder'])\n",
    "df2.sort_values(by=['Folder'], inplace=True)\n",
    "df2 = df2.iloc[1::,0]\n",
    "df2 = df2.reset_index(drop=True)\n",
    "largo_data = df2.count()\n",
    "file_extension = '.csv'\n",
    "\n",
    "\n",
    "#by folders\n",
    "All_colonies=pd.DataFrame()\n",
    "for x in range(largo_data): \n",
    "  csv_files = sorted(glob(MainFolder+'/' + df2[x] + '/*' + file_extension))\n",
    "  df = pd.concat((pd.read_csv(file).assign(filename = file) \n",
    "  for file in csv_files), ignore_index = False) #False si quiere mantener el index, True si no\n",
    "  df.to_csv(df2[x]+'.csv') #un archivo por carpeta\n",
    "  All_colonies = All_colonies.append(df)\n",
    "All_colonies.to_csv('All_colonies_positions.csv') #un archivo para todas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZ7rseRqfm_S"
   },
   "outputs": [],
   "source": [
    "#now, for summary\n",
    "\n",
    "data = os.listdir(MainFolder)\n",
    "df2 = pd.DataFrame(data, columns=[ 'Folder'])\n",
    "df2.sort_values(by=['Folder'], inplace=True)\n",
    "df2 = df2.iloc[1::,0]\n",
    "df2 = df2.reset_index(drop=True)\n",
    "largo_data = df2.count()\n",
    "file_extension = '.csv'\n",
    "#by folders\n",
    "All_colonies=pd.DataFrame()\n",
    "for x in range(largo_data): \n",
    "  csv_files = sorted(glob(MainFolder+'/' + df2[x] + '/*' + file_extension))\n",
    "  df = pd.concat((pd.read_csv(file).assign(filename = file).iloc[-1:]\n",
    "                  for file in csv_files), ignore_index = False)\n",
    "  \n",
    "df = df.reset_index().rename(columns={'index':'Count'})\n",
    "df['Count']=df['Count']+1 #agregarle 1 para que quede igual\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-YjPA2hjwkv"
   },
   "source": [
    "#Zona de prueb de Luna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jxNEnHgnkg_"
   },
   "outputs": [],
   "source": [
    "#Delete all folders\n",
    "#%rm -rf Image_analysis_folders\n",
    "%whos #show all active variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIeIqe5lnl7C"
   },
   "outputs": [],
   "source": [
    "#Image_analysis como funcion\n",
    "def Image_analysis(x,fnames,im_names):\n",
    "#ID bright and dapi\n",
    "  Im_ID = {}\n",
    "  Im_ID['dapi'] = fnames[x]\n",
    "  Im_ID['bf'] = fnames[x]\n",
    "\n",
    "  f_categories = list(Im_ID.keys())\n",
    "  for cat in f_categories:\n",
    "      print(str(cat) + ' file is: \\n'+ str(Im_ID[cat]) +'\\n' )\n",
    "  # to store the related image source\n",
    "  # also define a vector with the channels\n",
    "  im_data={}\n",
    "  im_data['R'],im_data['G'],im_data['B'],im_data['NormSum'] = get_im_data(fnames)\n",
    "  im_data['name']=fnames    \n",
    "  CHANNELS = ['R','G','B']\n",
    "\n",
    "  #initialize the dictionaries to store the data\n",
    "  sImS = {}\n",
    "  sImSall = {}\n",
    "  detected={}\n",
    "  filter_sigma = {}\n",
    "  threshold = {}\n",
    "  sigma_lim = {}\n",
    "  \n",
    "  #Fill this two variables to set the filter properties\n",
    "  im_num = x\n",
    "  filter_sigma[im_num] = 0.4\n",
    "\n",
    "  print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "  #### apply the filter\n",
    "  sImS[im_num],sImSall[im_num] = smooth_data(im_data,filter_sigma[im_num],im_num)\n",
    "\n",
    "  # perform a Zoom by slicing the image:\n",
    "\n",
    "  # modify next values accord the section you want to see:\n",
    "\n",
    "  x_lims = [1000,1500]    \n",
    "  y_lims = [1500,2000]    \n",
    "\n",
    "  #######################\n",
    "  # Just make the plot ###\n",
    "  ########################\n",
    "  im_zoom(x_lims, y_lims, sImSall[im_num])\n",
    "\n",
    "  # assign the stimated radius value in pixel units\n",
    "\n",
    "  Rmin = 1   # --> this should be estimated based on microscope resolution and bacterial size\n",
    "  Rmax = 10\n",
    "\n",
    "  #perform the sigma limits computation:\n",
    "  sigma_lim[im_num] = [Rmin/(2**0.5),Rmax/(2**0.5)]\n",
    "  print('sigma limits are: ' + str(sigma_lim[im_num]))\n",
    "\n",
    "  #define a Threshold\n",
    "  threshold[im_num]=0.7 #CAMBIE ESTO PARA LOS CUPONES\n",
    "\n",
    "  ##########################\n",
    "  ## evaluate it visually ##\n",
    "  ##########################\n",
    "\n",
    "  # whole image\n",
    "  thr_im = sImSall[im_num]>threshold[im_num]\n",
    "  #plt.imshow(thr_im)\n",
    "\n",
    "  # zoom\n",
    "  x_lims = [1000,2000]    \n",
    "  y_lims = [2000,3000]    \n",
    "  im_zoom(x_lims, y_lims, thr_im, colorbar = False)\n",
    "\n",
    "  ## Fill this two parameters only if you want to use a smaller region of the image (it's useful to verify the correct parameter choise)\n",
    "  x_lims = [1000,2000]    \n",
    "  y_lims = [2000,3000] \n",
    "\n",
    "  #########################\n",
    "  ### detect the images ###\n",
    "  #########################\n",
    "\n",
    "  detected[im_num]=colony_blobs_id(sImSall[im_num], threshold[im_num], fnames[im_num], sigma_lim[im_num])#, xlim=x_lim, ylim=y_lim) \n",
    "  \n",
    "  y_zoom = [500,800]\n",
    "  x_zoom = [200,500]\n",
    "  colony_plot(detected[im_num], fnames[im_num], y_zoom, x_zoom)\n",
    "\n",
    "  # image number correspont to the brighfield\n",
    "  bf_num = im_data['name'].index(Im_ID['bf'])\n",
    "  print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "  ###########################################################\n",
    "  # fill this variable with desired filter parameter value:\n",
    "\n",
    "  filter_sigma[bf_num] = 0.5\n",
    "  ############################################################\n",
    "\n",
    "  # Apply the filter\n",
    "  sImS[bf_num],sImSall[bf_num] = smooth_data(im_data,filter_sigma[bf_num],bf_num)\n",
    "\n",
    "\n",
    "  bf_cols = {}\n",
    "\n",
    "  ####################################################\n",
    "  ## Fill this parameters based on the image values ##\n",
    "\n",
    "  thresh_up = 3   # grain threshold\n",
    "  thresh_low = 0     # border threshold\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  bf_cols[\"bf_threshold\"] = [thresh_up, thresh_low]  # save the used values\n",
    "  bin_bf, grain_area = binary_image(sImSall[bf_num], thresh_up, thresh_low)\n",
    "\n",
    "  print(\"image percent \" + str(grain_area/bin_bf.size))\n",
    "\n",
    "  ###################################################################\n",
    "\n",
    "  image = 'dapi'   # write \"dapi\" or \"dii\"\n",
    "\n",
    "  ###################################################################\n",
    "  im_num = im_data['name'].index(Im_ID[image])\n",
    "  print('working on \"' + im_data['name'][im_num].split(\"\\\\\")[-1]+ '\"')\n",
    "\n",
    "  bf_cols[im_num] =  np.asarray(Bfield_filter(detected[im_num], bin_bf))\n",
    "  y_zoom = [200,600]\n",
    "  x_zoom = [300,780]\n",
    "  #colony_plot(bf_cols[im_num], fnames[im_num], ylim = y_zoom, xlim = x_zoom)\n",
    "  #print('grain filtered colonies')\n",
    "\n",
    "  #colony_plot(detected[im_num], fnames[im_num], ylim = y_zoom, xlim = x_zoom)\n",
    "\n",
    "  #print('previous grain filter')\n",
    "  return(im_data, bf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSm_svLAntOa"
   },
   "outputs": [],
   "source": [
    "##tellme how many .csv are in each folder ##yes, I just reused the code\n",
    "data = os.listdir(MainFolder)\n",
    "df = pd.DataFrame(data, columns=[ 'Folder'])\n",
    "df.sort_values(by=['Folder'], inplace=True)\n",
    "df = df.iloc[1::,0]\n",
    "df = df.reset_index(drop=True)\n",
    "largo_data = df.count()\n",
    "\n",
    "for y in range(largo_data): \n",
    "  nested_folder = (MainFolder + \"/\" + df[y])\n",
    "  fpath = os.path.abspath(nested_folder)\n",
    "  im_names, fnames = file_names(fpath,im_extension)\n",
    "  fnamesCSV = []\n",
    "  fnamesCSV = [x for x in fnames if x.endswith('.csv')] ############### to filter out folders with .csv\n",
    "  how_long = len(fnamesCSV)\n",
    "  how_long = str(how_long)\n",
    "  print(df[y]+' has '+how_long+'.csv files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lfT8inWn_x5"
   },
   "outputs": [],
   "source": [
    "#Para que corra Image_analysis!\n",
    "#Edition so it wont run folders with .csv\n",
    "data = os.listdir(MainFolder)\n",
    "df = pd.DataFrame(data, columns=[ 'Folder'])\n",
    "df.sort_values(by=['Folder'], inplace=True)\n",
    "df = df.iloc[1::,0]\n",
    "df = df.reset_index(drop=True)\n",
    "largo_data = df.count()\n",
    "for y in range(largo_data): \n",
    "  nested_folder = (MainFolder + \"/\" + df[y])\n",
    "  fpath = os.path.abspath(nested_folder)\n",
    "  im_names, fnames = file_names(fpath,im_extension)\n",
    "  CHANNELS = ['R','G','B'] ########\n",
    "  fnamesCSV = []\n",
    "  fnamesCSV = [x for x in fnames if x.endswith('.csv')] ############### to filter out folders with .csv\n",
    "  if len(fnamesCSV) == 16:\n",
    "    print(df[y]+' already has .csv files')\n",
    "  else:\n",
    "    for x in range (16):\n",
    "      plt.close('all')  ###a ver si funciona :)\n",
    "      Im = np.array([])  ############## trying to delete/empty arrays so it wont use all the ram\n",
    "      im = np.array([])  ############### up\n",
    "      im_data, bf_cols = Image_analysis(x,fnames,im_names)\n",
    "      Im_ID = {}\n",
    "      Im_ID['dapi'] = fnames[x]\n",
    "      Im_ID['bf'] = fnames[x]\n",
    "      im_clases = ['dapi']        # They have to be in Im_ID.keys()\n",
    "      Headers = ['Dye', 'Y', 'X', 'Sigma' , 'Radii', 'ID']   # Y to ID are in \"detected\"\n",
    "      exp_name = fnames[x]   # experiment name to be create the file                            #######\n",
    "      with open(exp_name+'.csv', 'w') as csvfile:\n",
    "          filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "          filewriter.writerow(Headers)\n",
    "          for image in im_clases:\n",
    "              im_num = im_data['name'].index(Im_ID[image])\n",
    "              for colony in bf_cols[im_num]:\n",
    "                  new_line = [image]\n",
    "                  for value in colony:\n",
    "                      new_line.append(value)\n",
    "                    \n",
    "                  filewriter.writerow(new_line)\n",
    "plt.close('all')  ###a ver si funciona :)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QkoUQ-QsEty7"
   ],
   "name": " Image analysis automatic tiles and folders.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
